# -*- coding: utf-8 -*-
"""Run_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A5c24hkamtekuerEUO_IB9xFeLWW9-ig
"""

#!pip freeze > requirements.txt

"""!!!
#install pytorch packagess

"""
#!pip install nltk
#!pip install tensorflow
#!pip install h5py
#!pip install -q transformers
#!pip install torch
#!pip install torchvision
#!pip install scikit-metrics

#!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html
#!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html
#!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git


"""!!!
#install scipy and networkx packages
"""

#!pip install 'scipy>=1.8'
#!pip install 'networkx<2.7'

"""# extract all"""

#from google.colab import drive
#rive.mount('/content/drive')

"""!!!
#read dataset from drive
"""

"""
import torch
dataFromGraphFile = torch.load("/content/drive/MyDrive/master-project-github/Main-Project/Run-Model/Graph_Own_0.5.pt")
"""

"""
you can run this model with this command that is mentioned in below.
!!!!!
  
  python run_model.py "../../graph-files/Graph_Own_0.5.pt"

!!!!
"""
# get graph name using argument
import sys
import torch


GRAPH_FILE_STARTER_NAME = "Graph"
GRAPH_SAVE_FILE_TYPE= ".pt"
GENERATED_NEGATIVE_EDGE_FOLDER="../../source-files/generated-negative-egdes/"

datasetNameStartIndex = sys.argv[1].index(GRAPH_FILE_STARTER_NAME)
datasetNameEndIndex = sys.argv[1].index(GRAPH_SAVE_FILE_TYPE)

datasetName = sys.argv[1][datasetNameStartIndex:datasetNameEndIndex]
print("datasetName : ", datasetName)


dataFromGraphFile = torch.load(sys.argv[1])
print("Graph file  : ",dataFromGraphFile)


def gatherDatasetInfo(dataset):
  print("Gather Dataset Info function is started")
  index = 0
  indexGene = 0
  indexDisease = 0
  indexGeneGene = 0
  indexDiseaseDisease = 0
  indexGeneDisease = 0
  while(index<len(dataset.gene_smybol)):
    firstNode = dataset.gene_smybol[index]
    if(firstNode == ""):
      indexDisease+=1
    else:
      indexGene+=1

    index+=1
  index=0
  while(index<len(dataset.edge_index[0])):
    if(dataset.edge_index[0][index]<=dataset.edge_index[1][index]):
      firstNode = dataset.gene_smybol[dataset.edge_index[0][index]]
      secondNode = dataset.gene_smybol[dataset.edge_index[1][index]]


      if(secondNode == "" and firstNode == ""):
        indexDiseaseDisease+=1
      elif(secondNode != "" and firstNode == ""):
        indexGeneDisease+=1
      elif(secondNode == "" and firstNode != ""):
        indexGeneDisease+=1
      elif(secondNode != "" and firstNode != ""):
        indexGeneGene+=1
    index+=1
  print("\nGene number : ", indexGene, " Disease number : ", indexDisease, " Gene-gene edge number : ", indexGeneGene, " Disease-disease edge number : ", indexDiseaseDisease, " Gene-disease edge number : ", indexGeneDisease, " \n")


gatherDatasetInfo(dataFromGraphFile)


"""
print(dataFromGraphFile)
print(dataFromGraphFile.gene_smybol[0])
print(dataFromGraphFile.gene_smybol[1])
print("Graph info is gathered")

def gatherDiseaseGeneEdgeIndex(dataset):
  print(dataset.edge_index)
  print(len(dataset.edge_index[0]))
  onlyGeneDiseaseTensor = [[],[]]
  index = 0
  while(index<len(dataset.edge_index[0])):
    firstNode=dataset.gene_smybol[dataset.edge_index[0][index]]
    secondNode=dataset.gene_smybol[dataset.edge_index[1][index]]
    if((firstNode == "" and secondNode != "") or (firstNode != "" and secondNode == "")):
      onlyGeneDiseaseTensor[0].append(dataset.edge_index[0][index])
      onlyGeneDiseaseTensor[1].append(dataset.edge_index[1][index])
    index+=1
  
  list_to_tensor = torch.tensor(onlyGeneDiseaseTensor)
  print("Our New 2D Tensor from 2D List is: \n", list_to_tensor)
  print("len", len(list_to_tensor[0]))

  return list_to_tensor

print("gatherDiseaseGeneEdgeIndex will run")
gatherDiseaseGeneEdgeIndex(dataFromGraphFile)
"""
"""
# check all negative edges is not in real edges class


negativeEdgeIndex = torch.load(GENERATED_NEGATIVE_EDGE_FOLDER+"generatedNegativeEdges_"+datasetName+GRAPH_SAVE_FILE_TYPE)
indexNegative=0
while(indexNegative<len(negativeEdgeIndex[0])):
  indexPositive=0
  while(indexPositive<len(dataFromGraphFile.edge_index[0])):
    if((negativeEdgeIndex[0][indexNegative]==dataFromGraphFile.edge_index[0][indexPositive]  and negativeEdgeIndex[1][indexNegative] == dataFromGraphFile.edge_index[1][indexPositive]) or (negativeEdgeIndex[1][indexNegative]==dataFromGraphFile.edge_index[0][indexPositive]  and negativeEdgeIndex[0][indexNegative] == dataFromGraphFile.edge_index[1][indexPositive])):
      print("probelem osman")  
    indexPositive+=1
  if(indexNegative%100 == 0):
    print(indexNegative)
  indexNegative+=1  
"""
"""#init variables"""

import numpy as np

# null numpy array
train_edges_list = []
test_edges_list = []
val_edges_list = []



#mask operation
mask = dataFromGraphFile.edge_index[0] <= dataFromGraphFile.edge_index[1]

#edgeIndexArray is built
edgeIndexArray = mask.nonzero(as_tuple=False).view(-1)

totalEdgeNumber = len(edgeIndexArray)

maxEdgeNumber = len(dataFromGraphFile.edge_index[0])

#init ratios
val_ratio = 0.1
test_ratio = 0.2
train_ratio = 1-val_ratio-test_ratio



#init index values
trainEdgeIndex = 0
valEdgeIndex = 0
testEdgeIndex = 0

#init index values
trainEdgeIndexGeneDisease = 0
valEdgeIndexGeneDisease = 0
testEdgeIndexGeneDisease = 0

#init index values
trainEdgeIndexGeneGene = 0
valEdgeIndexGeneGene = 0
testEdgeIndexGeneGene = 0

#init index values
trainEdgeIndexDiseaseDisease = 0
valEdgeIndexDiseaseDisease = 0
testEdgeIndexDiseaseDisease = 0



#build gene-disease index dict
geneDiseaseEdgeIndexDict = {}

#build gene id array
processedGeneId = []

# null numpy array
train_edges_list = []
test_edges_list = []
val_edges_list = []

# edge number between disease-gene or vice-versa

numberOfEdgeBetweenDiseaseGene = 0

numberOfEdgeBetweenGeneGene = 0
numberOfEdgeBetweenDiseaseDisease = 0

def initVariables():
  global edgeIndexArray
  global totalEdgeNumber
  global val_ratio
  global test_ratio
  global train_ratio
  global train_edges
  global test_edges
  global val_edges
  global train_val_edges
  global trainEdgeIndex
  global testEdgeIndex
  global valEdgeIndex

  global trainEdgeIndexGeneDisease
  global testEdgeIndexGeneDisease
  global valEdgeIndexGeneDisease

  global trainEdgeIndexGeneGene
  global testEdgeIndexGeneGene
  global valEdgeIndexGeneGene

  global trainEdgeIndexDiseaseDisease
  global testEdgeIndexDiseaseDisease
  global valEdgeIndexDiseaseDisease

  global maxTrainEdgeIndex
  global maxValEdgeIndex
  global maxTestEdgeIndex
  global geneDiseaseEdgeIndexDict

  global train_edges_numpy
  global test_edges_numpy
  global val_edges_numpy

  global train_edges_list
  global test_edges_list
  global val_edges_list

  global numberOfEdgeBetweenDiseaseGene
  global numberOfEdgeBetweenDiseaseDisease
  global numberOfEdgeBetweenGeneGene

  global maxEdgeNumber

  global edge_index_label_temp

  #mask operation
  mask = dataFromGraphFile.edge_index[0] <= dataFromGraphFile.edge_index[1]

  #edgeIndexArray is built
  edgeIndexArray = mask.nonzero(as_tuple=False).view(-1)

  totalEdgeNumber = len(edgeIndexArray)

  maxEdgeNumber = len(dataFromGraphFile.edge_index[0])

  #init ratios
  val_ratio = 0.1
  test_ratio = 0.2
  train_ratio = 1-val_ratio-test_ratio


  train_val_edges = torch.empty(1)
  train_edges = torch.empty(1)
  test_edges = torch.empty(1)
  val_edges = torch.empty(1)

  #init index values
  trainEdgeIndex = 0
  valEdgeIndex = 0
  testEdgeIndex = 0


  #build gene-disease index dict
  geneDiseaseEdgeIndexDict = {}

  #build gene id array
  processedGeneId = []

  # null numpy array
  train_edges_list = []
  test_edges_list = []
  val_edges_list = []

  #edg_label_index
  edge_index_label_temp = []

  numberOfEdgeBetweenDiseaseGene = 0
  numberOfEdgeBetweenGeneGene = 0
  numberOfEdgeBetweenDiseaseDisease = 0

  #init index values
  trainEdgeIndexGeneDisease = 0
  valEdgeIndexGeneDisease = 0
  testEdgeIndexGeneDisease = 0

  #init index values
  trainEdgeIndexGeneGene = 0
  valEdgeIndexGeneGene = 0
  testEdgeIndexGeneGene = 0

  #init index values
  trainEdgeIndexDiseaseDisease = 0
  valEdgeIndexDiseaseDisease = 0
  testEdgeIndexDiseaseDisease = 0

def getNumberOfEdgesBetweenDiseaseGene():
  global numberOfEdgeBetweenDiseaseGene
  global maxTrainEdgeIndex
  global maxTestEdgeIndex
  global maxValEdgeIndex
  global train_ratio
  global test_ratio
  global val_ratio
  index = 0
  while(index<maxEdgeNumber):
    if(dataFromGraphFile.edge_index[0][index]<=dataFromGraphFile.edge_index[1][index]):
      firstNode = True if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[0][index]]!="") else False
      firstNodeID = "" if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[0][index]]=="") else dataFromGraphFile.id[dataFromGraphFile.edge_index[0][index]]
      # check second node is gene or not
      # if node is gene it is assigned to True, otherwise assigned False
      secondNode = True if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[1][index]]!="") else False
      secondNodeID = "" if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[1][index]]=="") else dataFromGraphFile.id[dataFromGraphFile.edge_index[1][index]]
      if(firstNode and not secondNode):
        numberOfEdgeBetweenDiseaseGene+=1
      elif(not firstNode and secondNode):
        numberOfEdgeBetweenDiseaseGene+=1
    index+=1
  maxTrainEdgeIndex = numberOfEdgeBetweenDiseaseGene * train_ratio
  maxTestEdgeIndex = numberOfEdgeBetweenDiseaseGene * test_ratio
  maxValEdgeIndex = numberOfEdgeBetweenDiseaseGene * val_ratio

def getNumberOfEdgesBetweenGeneGeneOrDiseaseDisease():
  global numberOfEdgeBetweenGeneGene
  global numberOfEdgeBetweenDiseaseDisease
  index = 0
  while(index<maxEdgeNumber):
    if(dataFromGraphFile.edge_index[0][index]<=dataFromGraphFile.edge_index[1][index]):
      firstNode = True if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[0][index]]!="") else False
      firstNodeID = "" if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[0][index]]=="") else dataFromGraphFile.id[dataFromGraphFile.edge_index[0][index]]
      # check second node is gene or not
      # if node is gene it is assigned to True, otherwise assigned False
      secondNode = True if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[1][index]]!="") else False
      secondNodeID = "" if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[1][index]]=="") else dataFromGraphFile.id[dataFromGraphFile.edge_index[1][index]]
      if(firstNode and  secondNode):
        numberOfEdgeBetweenGeneGene+=1
      elif(not firstNode and not secondNode):
        numberOfEdgeBetweenDiseaseDisease+=1
    index+=1


# !
import csv
rowsUniref50 = []
with open("../../graph-files/GeneFeatures_Uniref50.csv", "r") as file:
    csvreader = csv.reader(file)
    headerUniref50 = next(csvreader)
    for row in csvreader:
        rowsUniref50.append(row)

print(headerUniref50)
print(rowsUniref50[0])

dictUniref50={}
for element in rowsUniref50:
  if(len(element)>11):
    dictUniref50[element[2]] = element[11]
  #else:
    #print("Problem in geneid : ", element[0])
print(dictUniref50.get("P04217"))

print("Uniref50 info is gathered")

def buildGeneDiseaseEdgeIndexDict():
  global maxEdgeNumber
  index = 0
  while(index<maxEdgeNumber):
    global geneDiseaseEdgeIndexDict

    # checn edge_index[0] is lower or equal with dataFromGraphFile.edge_index[1][index]
    if(dataFromGraphFile.edge_index[0][index]<=dataFromGraphFile.edge_index[1][index]):
      # check first node is gene or not
      # if node is gene it is assigned to True, otherwise assigned False
      firstNode = True if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[0][index]]!="") else False
      firstNodeID = "" if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[0][index]]=="") else dataFromGraphFile.id[dataFromGraphFile.edge_index[0][index]]
      # check second node is gene or not
      # if node is gene it is assigned to True, otherwise assigned False
      secondNode = True if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[1][index]]!="") else False
      secondNodeID = "" if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[1][index]]=="") else dataFromGraphFile.id[dataFromGraphFile.edge_index[1][index]]
      if(firstNode and not secondNode):
        if(geneDiseaseEdgeIndexDict.get(firstNodeID) != None and geneDiseaseEdgeIndexDict.get(firstNodeID) != "" and geneDiseaseEdgeIndexDict.get(firstNodeID) != []):
          tempList = geneDiseaseEdgeIndexDict.get(firstNodeID)
          tempList.append(index)
          geneDiseaseEdgeIndexDict[firstNodeID] = tempList
        else:
          tempList=[]
          tempList.append(index)
          geneDiseaseEdgeIndexDict[firstNodeID] = tempList
      elif(not firstNode and secondNode):
        if(geneDiseaseEdgeIndexDict.get(secondNodeID) != None and geneDiseaseEdgeIndexDict.get(secondNodeID) != "" and geneDiseaseEdgeIndexDict.get(secondNodeID) != []):
          tempList = geneDiseaseEdgeIndexDict.get(secondNodeID)
          tempList.append(index)
          geneDiseaseEdgeIndexDict[secondNodeID] = tempList
        else:
          tempList=[]
          tempList.append(index)
          geneDiseaseEdgeIndexDict[secondNodeID] = tempList
    index+=1

buildGeneDiseaseEdgeIndexDict()

"""
for key, value in geneDiseaseEdgeIndexDict.items():
    print(key, ' : ', value)
"""
"""# functions using dict"""

def inList(geneID):
  global processedGeneId
  if geneID in processedGeneId:
    return True
  else:
    return False

###################################################################################
def processGeneIdTrainFromDict(geneID):
  global trainEdgeIndex
  global maxTrainEdgeIndex
  global train_edges_list
  global geneDiseaseEdgeIndexDict
  global processedGeneId
  global numberOfEdgeBetweenDiseaseGene
  global trainEdgeIndexGeneDisease
  #print("processGeneIdTrain is start : ", geneID)
  # check geneId is processed or not
  if(not inList(geneID)):
    #geneid in genediseaseEdgeIndexdict
    if( geneID in geneDiseaseEdgeIndexDict.keys()):
      # check trainEdgeIndex maximum number
      if(trainEdgeIndex < maxTrainEdgeIndex + len(geneDiseaseEdgeIndexDict.get(geneID)) and trainEdgeIndexGeneDisease <numberOfEdgeBetweenDiseaseGene*train_ratio):
          train_edges_list.extend(geneDiseaseEdgeIndexDict.get(geneID))
          trainEdgeIndex += len(geneDiseaseEdgeIndexDict.get(geneID))
          trainEdgeIndexGeneDisease += len(geneDiseaseEdgeIndexDict.get(geneID))
          #print("Train edge added : ", geneID," appended_len : ",len(geneDiseaseEdgeIndexDict.get(geneID))," trainEdgeIndexGeneDisease: ",trainEdgeIndexGeneDisease)

          #append geneID to processedGeneId list
          processedGeneId.append(geneID)

def processGeneIdTestFromDict(geneID):
  global testEdgeIndex
  global maxTestEdgeIndex
  global test_edges_list
  global geneDiseaseEdgeIndexDict
  global processedGeneId
  global numberOfEdgeBetweenDiseaseGene
  global testEdgeIndexGeneDisease
  #print("processGeneIdTest is start : ", geneID)
  # check geneId is processed or not
  if(not inList(geneID)):
    #geneid in genediseaseEdgeIndexdict
    if( geneID in geneDiseaseEdgeIndexDict.keys()):
      # check trainEdgeIndex maximum number
      if(testEdgeIndex<maxTestEdgeIndex + len(geneDiseaseEdgeIndexDict.get(geneID)) and testEdgeIndexGeneDisease<numberOfEdgeBetweenDiseaseGene*test_ratio):
          test_edges_list.extend(geneDiseaseEdgeIndexDict.get(geneID))
          testEdgeIndex += len(geneDiseaseEdgeIndexDict.get(geneID))
          testEdgeIndexGeneDisease += len(geneDiseaseEdgeIndexDict.get(geneID))
          #print("Test edge added : ", geneID," appended_len : ",len(geneDiseaseEdgeIndexDict.get(geneID))," testEdgeIndexGeneDisease: ",testEdgeIndexGeneDisease)

          #append geneID to processedGeneId list
          processedGeneId.append(geneID)

def processGeneIdValFromDict(geneID):
  global valEdgeIndex
  global maxValEdgeIndex
  global val_edges_list
  global geneDiseaseEdgeIndexDict
  global processedGeneId
  global numberOfEdgeBetweenDiseaseGene
  global valEdgeIndexGeneDisease
  #print("processGeneIdVal is start : ", geneID)
  # check geneId is processed or not
  if(not inList(geneID)):
    #geneid in genediseaseEdgeIndexdict
    if( geneID in geneDiseaseEdgeIndexDict.keys()):
      # check trainEdgeIndex maximum number
      if(valEdgeIndex<maxValEdgeIndex + len(geneDiseaseEdgeIndexDict.get(geneID)) and valEdgeIndexGeneDisease<numberOfEdgeBetweenDiseaseGene*val_ratio):
          val_edges_list.extend(geneDiseaseEdgeIndexDict.get(geneID))
          valEdgeIndex += len(geneDiseaseEdgeIndexDict.get(geneID))
          valEdgeIndexGeneDisease +=len(geneDiseaseEdgeIndexDict.get(geneID))
          #print("Val edge added : ", geneID," appended_len : ",len(geneDiseaseEdgeIndexDict.get(geneID))," valEdgeIndexGeneDisease: ",valEdgeIndexGeneDisease)


          #append geneID to processedGeneId list
          processedGeneId.append(geneID)

"""# split edge based on geneDiseaseEdgeIndexDict"""

def splitEdgesBasedOnUniref50UsingDict():
  print("splitEdgesBasedOnUniref50UsingDict will be run")
  global edgeIndexArray
  global totalEdgeNumber
  global val_ratio
  global test_ratio
  global train_ratio
  global train_edges
  global test_edges
  global train_val_edges
  global val_edges
  global trainEdgeIndex
  global testEdgeIndex
  global valEdgeIndex

  global trainEdgeIndexGeneDisease
  global testEdgeIndexGeneDisease
  global valEdgeIndexGeneDisease

  global trainEdgeIndexGeneGene
  global testEdgeIndexGeneGene
  global valEdgeIndexGeneGene

  global trainEdgeIndexDiseaseDisease
  global testEdgeIndexDiseaseDisease
  global valEdgeIndexDiseaseDisease

  global maxTrainEdgeIndex
  global maxValEdgeIndex
  global maxTestEdgeIndex
  global geneDiseaseEdgeIndexDict

  global train_edges_numpy
  global test_edges_numpy
  global val_edges_numpy

  global train_edges_list
  global test_edges_list
  global val_edges_list

  global numberOfEdgeBetweenDiseaseGene
  global numberOfEdgeBetweenDiseaseDisease
  global numberOfEdgeBetweenGeneGene

  global maxEdgeNumber

  index=0
  maxTrainEdgeIndex = int(numberOfEdgeBetweenDiseaseGene * train_ratio)
  maxTestEdgeIndex = int(numberOfEdgeBetweenDiseaseGene * test_ratio)
  maxValEdgeIndex = int(numberOfEdgeBetweenDiseaseGene * val_ratio)

  while(index<maxEdgeNumber):
    """
    print(dataFromGraphFile.edge_index[0][index])
    print(dataFromGraphFile.edge_index[1][index])
    print(dataFromGraphFile.id[dataFromGraphFile.edge_index[0][index]])
    print(dataFromGraphFile.id[dataFromGraphFile.edge_index[1][index]])
    print(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[0][index]])
    print(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[1][index]])
    """
    # check dataFromGraphFile.edge_index[0][index] is less or equal with dataFromGraphFile.edge_index[1][index]
    if(dataFromGraphFile.edge_index[0][index]<=dataFromGraphFile.edge_index[1][index]):
      # check first node is gene or not
      # if node is gene it is assigned to True, otherwise assigned False
      firstNode = True if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[0][index]]!="") else False
      firstNodeID = "" if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[0][index]]=="") else dataFromGraphFile.id[dataFromGraphFile.edge_index[0][index]]
      # check second node is gene or not
      # if node is gene it is assigned to True, otherwise assigned False
      secondNode = True if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[1][index]]!="") else False
      secondNodeID = "" if(dataFromGraphFile.gene_smybol[dataFromGraphFile.edge_index[1][index]]=="") else dataFromGraphFile.id[dataFromGraphFile.edge_index[1][index]]


      # firstnode is gene and second node is disease, we want to gather this edge especially in test and val
      # firstNodeID is not null but, secondNodeID is null.
      if(firstNode and not secondNode):
        if(not inList(firstNodeID)):
          processGeneIdTestFromDict(firstNodeID)
          if(dictUniref50.get(firstNodeID)!="" and dictUniref50.get(firstNodeID)!=None):
            #print("Test uniret50 split :",dictUniref50.get(firstNodeID).split(","))
            for element in dictUniref50.get(firstNodeID).split(","):
              processGeneIdTestFromDict(element)
            #print("Test list len : ", len(test_edges_list))

        if(not inList(firstNodeID)):
          processGeneIdValFromDict(firstNodeID)
          if(dictUniref50.get(firstNodeID)!="" and dictUniref50.get(firstNodeID)!=None):
            #print("Val uniret50 split :",dictUniref50.get(firstNodeID).split(","))
            for element in dictUniref50.get(firstNodeID).split(","):
              processGeneIdValFromDict(element)
            #print("Val list len : ", len(val_edges_list))

        if(not inList(firstNodeID)):
          processGeneIdTrainFromDict(firstNodeID)
          if(dictUniref50.get(firstNodeID)!="" and dictUniref50.get(firstNodeID)!=None):
            #print("Train uniret50 split :",dictUniref50.get(firstNodeID).split(","))
            for element in dictUniref50.get(firstNodeID).split(","):
              processGeneIdTrainFromDict(element)
            #print("Train list len : ", len(train_edges_list))


      # firstnode is disease and second node is gene, we want to gather this edge especially in val and test
      elif(not firstNode and secondNode):

        if(not inList(secondNodeID)):
          processGeneIdTestFromDict(secondNodeID)
          if(dictUniref50.get(secondNodeID)!="" and dictUniref50.get(secondNodeID)!=None):
            #print("Test uniret50 split :",dictUniref50.get(secondNodeID).split(","))
            for element in dictUniref50.get(secondNodeID).split(","):
              processGeneIdTestFromDict(element)
            #print("Test list len : ", len(test_edges_list))

        if(not inList(secondNodeID)):
          processGeneIdValFromDict(secondNodeID)
          if(dictUniref50.get(secondNodeID)!="" and dictUniref50.get(secondNodeID)!=None):
            #print("Val uniret50 split :",dictUniref50.get(secondNodeID).split(","))
            for element in dictUniref50.get(secondNodeID).split(","):
              processGeneIdValFromDict(element)
            #print("Val list len : ", len(val_edges_list))

        if(not inList(secondNodeID)):
          processGeneIdTrainFromDict(secondNodeID)
          if(dictUniref50.get(secondNodeID)!="" and dictUniref50.get(secondNodeID)!=None):
            #print("Train uniret50 split :",dictUniref50.get(secondNodeID).split(","))
            for element in dictUniref50.get(secondNodeID).split(","):
              processGeneIdTrainFromDict(element)
            #print("Train list len : ", len(train_edges_list))

      # firstnode is gene and second node is gene, we want to gather this edge especially in train and val

      elif(firstNode and secondNode):
        edge_index_label_temp.append(index)
        """
        if(maxTrainEdgeIndex>trainEdgeIndex and trainEdgeIndexGeneGene<numberOfEdgeBetweenGeneGene*train_ratio):
          train_edges_list.append(index)
          trainEdgeIndex+=1
          trainEdgeIndexGeneGene+=1
        elif(maxValEdgeIndex>valEdgeIndex and valEdgeIndexGeneGene<numberOfEdgeBetweenGeneGene*val_ratio):
          val_edges_list.append(index)
          valEdgeIndex+=1
          valEdgeIndexGeneGene+=1
        elif(maxTestEdgeIndex>testEdgeIndex and testEdgeIndexGeneGene<numberOfEdgeBetweenGeneGene*test_ratio):
          test_edges_list.append(index)
          testEdgeIndex+=1
          testEdgeIndexGeneGene+=1
          """

      # firstnode is disease and second node is disease, we want to gather this edge especially in train and val
      elif(not firstNode and not secondNode):
        edge_index_label_temp.append(index)
        """
        if(maxTrainEdgeIndex>trainEdgeIndex and trainEdgeIndexDiseaseDisease<numberOfEdgeBetweenDiseaseDisease*train_ratio):
          train_edges_list.append(index)
          trainEdgeIndex+=1
          trainEdgeIndexDiseaseDisease+=1
        elif(maxValEdgeIndex>valEdgeIndex and valEdgeIndexDiseaseDisease<numberOfEdgeBetweenDiseaseDisease*val_ratio):
          val_edges_list.append(index)
          valEdgeIndex+=1
          valEdgeIndexDiseaseDisease+=1
        elif(maxTestEdgeIndex>testEdgeIndex and testEdgeIndexDiseaseDisease<numberOfEdgeBetweenDiseaseDisease*test_ratio):
          test_edges_list.append(index)
          testEdgeIndex+=1
          testEdgeIndexDiseaseDisease+=1
        """


    """
    if(index%1000 == 0):
      print("splitEdgesBasedOnUniref50UsingDict function is running, index : ", index)
    """
    index = index  +  1

  train_edges = torch.tensor(train_edges_list)
  test_edges = torch.tensor(test_edges_list)
  val_edges = torch.tensor(val_edges_list)


  train_val_edges = torch.tensor(train_edges_list + val_edges_list)

def buildEdgeLabelIndex(edge_index_label_temp):
  index= 0
  edge_label_index2 = torch.zeros([2, len(edge_index_label_temp)], dtype=torch.int32)
  edge_label2 = torch.ones([len(edge_index_label_temp)], dtype=torch.int32)
  print(edge_label_index2)
  print(edge_label2)
  while(index<len(edge_index_label_temp)):
    edge_label_index2[0][index] = dataFromGraphFile.edge_index[0][edge_index_label_temp[index]]
    edge_label_index2[1][index] = dataFromGraphFile.edge_index[1][edge_index_label_temp[index]]
    index+=1
  return edge_label_index2, edge_label2

"""
edge_label_index2, edge_label2 = buildEdgeLabelIndex(edge_index_label_temp)
print(edge_label_index2)
print(edge_label2)
"""

def getEdgeLabelIndexFromIndex(indexList):
  edge_label_index = torch.zeros([2, len(indexList)], dtype=torch.int32)
  #edge_label = torch.ones([len(indexList)], dtype=torch.int32)
  index = 0
  while(index<len(indexList)):
    edge_label_index[0][index] = dataFromGraphFile.edge_index[0][indexList[index]]
    edge_label_index[1][index] = dataFromGraphFile.edge_index[1][indexList[index]]
    index+=1
  return edge_label_index

print("KZCLinkSplit implementation is initialized")

"""# KZClinkSplit

"""

from typing import Union, Tuple

import copy

import torch
from torch import Tensor

# build negative edges based on random negative edge generator
import random
# gather time info
from datetime import datetime
# run multithread
import threading
from multiprocessing.pool import ThreadPool

from torch_geometric.data import Data
from torch_geometric.utils import add_self_loops, negative_sampling
from torch_geometric.transforms import BaseTransform
import os.path


class KZCLinkSplit(BaseTransform):
    r"""Performs an edge-level random split into training, validation and test
    sets.
    The split is performed such that the training split does not include edges
    in validation and test splits; and the validation split does not include
    edges in the test split.

    .. code-block::

        from torch_geometric.transforms import RandomLinkSplit

        transform = RandomLinkSplit(is_undirected=True)
        train_data, val_data, test_data = transform(data)

    Args:
        num_val (int or float, optional): The number of validation edges.
            If set to a floating-point value in :math:`[0, 1]`, it represents
            the ratio of edges to include in the validation set.
            (default: :obj:`0.1`)
        num_test (int or float, optional): The number of test edges.
            If set to a floating-point value in :math:`[0, 1]`, it represents
            the ratio of edges to include in the test set.
            (default: :obj:`0.2`)
        is_undirected (bool): If set to :obj:`True`, the graph is assumed to be
            undirected, and positive and negative samples will not leak
            (reverse) edge connectivity across different splits.
            (default: :obj:`False`)
        key (str, optional): The name of the attribute holding
            ground-truth labels.
            If :obj:`data[key]` does not exist, it will be automatically
            created and represents a binary classification task
            (:obj:`1` = edge, :obj:`0` = no edge).
            If :obj:`data[key]` exists, it has to be a categorical label from
            :obj:`0` to :obj:`num_classes - 1`.
            After negative sampling, label :obj:`0` represents negative edges,
            and labels :obj:`1` to :obj:`num_classes` represent the labels of
            positive edges. (default: :obj:`"edge_label"`)
        split_labels (bool, optional): If set to :obj:`True`, will split
            positive and negative labels and save them in distinct attributes
            :obj:`"pos_edge_label"` and :obj:`"neg_edge_label"`, respectively.
            (default: :obj:`False`)
        add_negative_train_samples (bool, optional): Whether to add negative
            training samples for link prediction.
            If the model already performs negative sampling, then the option
            should be set to :obj:`False`.
            Otherwise, the added negative samples will be the same across
            training iterations unless negative sampling is performed again.
            (default: :obj:`True`)
        neg_sampling_ratio: (float, optional): The ratio of sampled negative
            edges to the number of positive edges. (default: :obj:`1.0`)
    """
    def __init__(
        self,
        num_val: Union[int, float] = 0.1,
        num_test: Union[int, float] = 0.2,
        is_undirected: bool = False,
        key: str = 'edge_label',
        split_labels: bool = False,
        add_negative_train_samples: bool = True,
        neg_sampling_ratio: float = 1.0,
    ):
        self.num_val = num_val
        self.num_test = num_test
        self.is_undirected = is_undirected
        self.key = key
        self.split_labels = split_labels
        self.add_negative_train_samples = add_negative_train_samples
        self.neg_sampling_ratio = neg_sampling_ratio

        #gda index list
        self.gdaIndexList = []
        self.gdaIndexDict = {}

    def setLists(self,trainEdgeLabelIndex, valEdgeLabelIndex, testEdgeLabelIndex):
      self.trainEdgeLabelIndex = trainEdgeLabelIndex
      self.valEdgeLabelIndex = valEdgeLabelIndex
      self.testEdgeLabelIndex = testEdgeLabelIndex

    def __call__(self, data: Data) -> Tuple[Data, Data, Data]:
        perm = torch.randperm(data.num_edges, device=data.edge_index.device)
        if self.is_undirected:
            perm = perm[data.edge_index[0] <= data.edge_index[1]]

        num_val, num_test = self.num_val, self.num_test
        if isinstance(num_val, float):
            num_val = int(num_val * perm.numel())
        if isinstance(num_test, float):
            num_test = int(num_test * perm.numel())

        num_train = perm.numel() - num_val - num_test
        if num_train <= 0:
            raise ValueError("Insufficient number of edges for training.")

        train_edges = perm[:num_train]
        val_edges = perm[num_train:num_train + num_val]
        test_edges = perm[num_train + num_val:]
        train_val_edges = perm[:num_train + num_val]

        # Create data splits:
        train_data = self._split_data(data, train_edges)
        val_data = self._split_data(data, train_edges)
        test_data = self._split_data(data, train_val_edges)

        # Create negative samples:
        num_neg_train = 0
        if self.add_negative_train_samples:
            num_neg_train = len(self.trainEdgeLabelIndex[0])
        num_neg_val = len(self.valEdgeLabelIndex[0])
        num_neg_test = len(self.testEdgeLabelIndex[0])

        num_neg = num_neg_train + num_neg_val + num_neg_test
        path = GENERATED_NEGATIVE_EDGE_FOLDER + "generatedNegativeEdges_"+str(datasetName)+".pt"
        print(path)
        print(type(path))
        if(not os.path.isfile(path)):
          isExist = os.path.exists(GENERATED_NEGATIVE_EDGE_FOLDER)
          isFolderExist = os.path.exists(GENERATED_NEGATIVE_EDGE_FOLDER)
          if not isFolderExist:
            # Create a new directory because it does not exist
            os.makedirs(GENERATED_NEGATIVE_EDGE_FOLDER)
          # tempDataset = self.gatherDiseaseGeneEdgeIndex(data)
          # print("Dataset: ", tempDataset)
          print("asd")
          """
          neg_edge_index = negative_sampling(
            add_self_loops(data.edge_index)[0], num_nodes=data.num_nodes,
            num_neg_samples=num_neg, method='sparse')
          print("Negative edge index : ", str(neg_edge_index))
          print("Type: ", type(neg_edge_index))
          print("Len: ", len(neg_edge_index[0]))
          """
          neg_edge_index = self.generateNegativeGeneDiseaseEdges(data,num_neg)
          print("Negative edge index : ", str(neg_edge_index))
          print("Type: ", type(neg_edge_index))
          print("Len: ", len(neg_edge_index[0]))
          torch.save(neg_edge_index, path)

          print("Negative edges are created")
        else:
          neg_edge_index = torch.load(path)
          print("Negative edges are loaded")
        # Create labels:
        self._create_label(
            data,
            train_edges,
            neg_edge_index[:, num_neg_val + num_neg_test:],
            self.trainEdgeLabelIndex,
            out=train_data,
        )
        self._create_label(
            data,
            val_edges,
            neg_edge_index[:, :num_neg_val],
            self.valEdgeLabelIndex,
            out=val_data,
        )
        self._create_label(
            data,
            test_edges,
            neg_edge_index[:, num_neg_val:num_neg_val + num_neg_test],
            self.testEdgeLabelIndex,
            out=test_data,
        )

        return train_data, val_data, test_data

    def _split(self, edge_index: Tensor, index: Tensor) -> Tensor:
        edge_index = edge_index[:, index]


        if self.is_undirected:
            edge_index = torch.cat([edge_index, edge_index.flip([0])], dim=-1)

        return edge_index

    def _split_data(self, data: Data, index: Tensor) -> Data:
        num_edges = data.num_edges

        data = copy.copy(data)
        data.edge_index = self._split(data.edge_index, index)

        for key, value in data.items():
          if key == 'edge_index':
            continue

          if key == 'edge_nodes_attributes':
            continue
            if isinstance(value, Tensor) and value.size(0) == num_edges:
                value = value[index]
                if self.is_undirected:
                    value = torch.cat([value, value], dim=0)
                data[key] = value

        return data

    def gatherDiseaseGeneEdgeIndex(self,dataset):
      onlyGeneDiseaseTensor = [[],[]]
      index = 0
      while(index<len(dataset.edge_index[0])):
        firstNode=dataset.gene_smybol[dataset.edge_index[0][index]]
        secondNode=dataset.gene_smybol[dataset.edge_index[1][index]]
        if((firstNode == "" and secondNode != "") or (firstNode != "" and secondNode == "")):
          onlyGeneDiseaseTensor[0].append(dataset.edge_index[0][index])
          onlyGeneDiseaseTensor[1].append(dataset.edge_index[1][index])
        index+=1
      
      list_to_tensor = torch.tensor(onlyGeneDiseaseTensor)

      return list_to_tensor



    def generateNegativeGeneDiseaseEdges(self,dataset,numberOfNegativeEdges):
      try:
        onlyGeneDiseaseTensor = [[],[]]
        print(datetime.now()," Generate Negative Edges function is started")
        index = 0
        while(index<numberOfNegativeEdges):
          
          randomIndex1 = random.randint(0, len(dataset.gene_smybol)-1)
          randomIndex2 = random.randint(0, len(dataset.gene_smybol)-1)

          # check first node is gene or not
          firstNode = True if(dataset.gene_smybol[randomIndex1]!="") else False
          #firstNodeID = "" if(dataset.gene_smybol[randomIndex1]=="") else dataset.id[randomIndex1]
          # check second node is gene or not 
          # if node is gene it is assigned to True, otherwise assigned False
          secondNode = True if(dataset.gene_smybol[randomIndex2]!="") else False
          #secondNodeID = "" if(dataset.gene_smybol[randomIndex2]=="") else dataset.id[randomIndex2]
        
          if((firstNode and not secondNode) or ( not firstNode and secondNode)):
            if(not self.hasEdgeBetweenNodesBasedOnDict(dataset,randomIndex1,randomIndex2)):
              if(index%1000 == 0):
                print(datetime.now()," Index of the generateNegativeGeneDiseaseEdges : ", index," rand1: ",randomIndex1," rand2 : ", randomIndex2)
              #adding normal edge
              onlyGeneDiseaseTensor[0].append(randomIndex1)
              onlyGeneDiseaseTensor[1].append(randomIndex2)        
              index+=1


        
        list_to_tensor = torch.tensor(onlyGeneDiseaseTensor)

        return list_to_tensor
      except Exception as exc:
        print("generateNegativeGeneDiseaseEdges ",  exc)

    def hasEdgeBetweenNodes(self, dataset, randomIndex1, randomIndex2):
      try:
        index = 0
        hasEdge = False
        if(len(self.gdaIndexList) <= 0): 
          self.gdaIndexList = self.generateListOfGeneDiseaseAssociation(dataset)
        while(index<len(self.gdaIndexList)):
          if(dataset.edge_index[0][self.gdaIndexList[index]] == randomIndex1 and dataset.edge_index[1][self.gdaIndexList[index]] == randomIndex2):
            hasEdge = True
            return hasEdge
          elif(dataset.edge_index[1][self.gdaIndexList[index]] == randomIndex1 and dataset.edge_index[0][self.gdaIndexList[index]] == randomIndex2):
            hasEdge = True
            return hasEdge
          index+=1
        return hasEdge
      except Exception as exc:
        print("hasEdgeBetweenNodes " , exc)

    def hasEdgeBetweenNodesBasedOnDict(self, dataset, randomIndex1, randomIndex2):
      try:
        hasEdge = False
        if(not bool(self.gdaIndexDict)): 
          # older attempt to build a dictionary
          #self.gdaIndexDict = self.generateDictOfGeneDiseaseAssociationBasedOnGeneThreads(dataset)
          self.gdaIndexDict = self.generateDictIndexByIndexOnEdgeIndex(dataset)
        # check first node is gene or not
        firstNode = True if(dataset.gene_smybol[randomIndex1]!="") else False
        #firstNodeID = "" if(dataset.gene_smybol[randomIndex1]=="") else dataset.id[randomIndex1]
        # check second node is gene or not 
        # if node is gene it is assigned to True, otherwise assigned False
        secondNode = True if(dataset.gene_smybol[randomIndex2]!="") else False
        #secondNodeID = "" if(dataset.gene_smybol[randomIndex2]=="") else dataset.id[randomIndex2]
        if((firstNode and not secondNode)):
          diseaseIndexList = self.gdaIndexDict.get(randomIndex1)
          index = 0
          while(diseaseIndexList != None and index<len(diseaseIndexList)):
            if(dataset.edge_index[0][diseaseIndexList[index]] == randomIndex1 and dataset.edge_index[1][diseaseIndexList[index]] == randomIndex2):
              hasEdge = True
              return hasEdge
            elif(dataset.edge_index[1][diseaseIndexList[index]] == randomIndex1 and dataset.edge_index[0][diseaseIndexList[index]] == randomIndex2):
              hasEdge = True
              return hasEdge
            index+=1
        elif(not firstNode and secondNode):

          diseaseIndexList = self.gdaIndexDict.get(randomIndex2)
          index = 0
          while(diseaseIndexList != None and index<len(diseaseIndexList)):
            if(dataset.edge_index[0][diseaseIndexList[index]] == randomIndex1 and dataset.edge_index[1][diseaseIndexList[index]] == randomIndex2):
              hasEdge = True
              return hasEdge
            elif(dataset.edge_index[1][diseaseIndexList[index]] == randomIndex1 and dataset.edge_index[0][diseaseIndexList[index]] == randomIndex2):
              hasEdge = True
              return hasEdge
            index+=1

        return hasEdge
      except Exception as exc:
        print("hasEdgeBetweenNodesBasedOnDict " , exc, " ", self.gdaIndexDict[randomIndex1]," ", self.gdaIndexDict[randomIndex2])

    def generateListOfGeneDiseaseAssociation(self, dataset):
      try:
        if(len(self.gdaIndexList) > 0):
          print(datetime.now()," List of gda is initialized before")
          return self.gdaIndexList
        else:
          print(datetime.now()," list of gda initialization starts")
          index = 0
          while(index<len(dataset.edge_index[0])):
            if(dataset.edge_index[0][index]<=dataset.edge_index[1][index]):
              if(index%1000 == 0):
                print(datetime.now()," Index of the generateListOfGeneDiseaseAssociation : ", index)
              # check first node is gene or not
              firstNode = True if(dataset.gene_smybol[dataset.edge_index[0][index]]!="") else False
              #firstNodeID = "" if(dataset.gene_smybol[randomIndex1]=="") else dataset.id[randomIndex1]
              # check second node is gene or not 
              # if node is gene it is assigned to True, otherwise assigned False
              secondNode = True if(dataset.gene_smybol[dataset.edge_index[1][index]]!="") else False
              #secondNodeID = "" if(dataset.gene_smybol[randomIndex2]=="") else dataset.id[randomIndex2]
            
              if((firstNode and not secondNode) or ( not firstNode and secondNode)):
                self.gdaIndexList.append(index)
            index += 1
          print("GDA Index List len: ", len(self.gdaIndexList))
          return self.gdaIndexList
      except Exception as exc:
        print("generateListOfGeneDiseaseAssociation ", exc)

    def generateDictIndexByIndexOnEdgeIndex(self, dataset):
      try:
        if(bool(self.gdaIndexDict)): 
          print(datetime.now()," Dict of gda is initialized before")
          return self.gdaIndexDict
        else:
          print(datetime.now()," Dict of gda initialization starts")
          index = 0
          while(index<len(dataset.edge_index[0])):
            if(index%1000 == 0):
                print(datetime.now()," Index of the generateDictIndexByIndexOnEdgeIndex : ", index)
            if(dataset.edge_index[0][index]<=dataset.edge_index[1][index]):
              # check first node is gene or not
              firstNode = True if(dataset.gene_smybol[dataset.edge_index[0][index]]!="") else False
              #firstNodeID = "" if(dataset.gene_smybol[randomIndex1]=="") else dataset.id[randomIndex1]
              # check second node is gene or not 
              # if node is gene it is assigned to True, otherwise assigned False
              secondNode = True if(dataset.gene_smybol[dataset.edge_index[1][index]]!="") else False
              #secondNodeID = "" if(dataset.gene_smybol[randomIndex2]=="") else dataset.id[randomIndex2]
              if(firstNode and not secondNode):
                if(self.gdaIndexDict.get(dataset.edge_index[0][index]) == None):
                  self.gdaIndexDict[dataset.edge_index[0][index]] = [dataset.edge_index[0][index]]
                else:
                  self.gdaIndexDict[dataset.edge_index[0][index]].append(dataset.edge_index[0][index])
              elif(not firstNode and secondNode):
                if(self.gdaIndexDict.get(dataset.edge_index[1][index]) == None):
                  self.gdaIndexDict[dataset.edge_index[1][index]] = [dataset.edge_index[1][index]]
                else:
                  self.gdaIndexDict[dataset.edge_index[1][index]].append(dataset.edge_index[1][index])

            index += 1
          return self.gdaIndexDict
      except Exception as exc:
        print("generateDictIndexByIndexOnEdgeIndex ", exc)

    def generateDictOfGeneDiseaseAssociationBasedOnGene(self, dataset):
      # self.gdaIndexDict
      try:
        indexGDA = 0
        if(len(self.gdaIndexList) <= 0): 
          self.gdaIndexList = self.generateListOfGeneDiseaseAssociation(dataset)

        while(indexGDA<len(dataset.gene_smybol)):
          index = 0
          diseaseIndexList = []
          if(indexGDA%100 == 0):
            print(datetime.now()," Index of the generateDictOfGeneDiseaseAssociationBasedOnGene : ", indexGDA)
          while(index<len(self.gdaIndexList)):
            if(dataset.edge_index[0][self.gdaIndexList[index]]<=dataset.edge_index[1][self.gdaIndexList[index]]):
              # check first node is gene or not
              firstNode = True if(dataset.gene_smybol[dataset.edge_index[0][self.gdaIndexList[index]]]!="") else False
              #firstNodeID = "" if(dataset.gene_smybol[randomIndex1]=="") else dataset.id[randomIndex1]
              # check second node is gene or not 
              # if node is gene it is assigned to True, otherwise assigned False
              secondNode = True if(dataset.gene_smybol[dataset.edge_index[1][self.gdaIndexList[index]]]!="") else False
              #secondNodeID = "" if(dataset.gene_smybol[randomIndex2]=="") else dataset.id[randomIndex2]
            
              if((firstNode and not secondNode) and (dataset.edge_index[0][self.gdaIndexList[index]] == indexGDA)):
                diseaseIndexList.append(self.gdaIndexList[index])
              elif((not firstNode and secondNode) and (dataset.edge_index[1][self.gdaIndexList[index]] == indexGDA)):
                diseaseIndexList.append(self.gdaIndexList[index])

            index += 1

          self.gdaIndexDict[indexGDA] = diseaseIndexList
          indexGDA += 1
        return self.gdaIndexDict
      except Exception as exc:
        print("generateDictOfGeneDiseaseAssociationBasedOnGene ", exc)

    # not big performance difference is gathered
    def generateDictOfGeneDiseaseAssociationBasedOnGeneThreads(self, dataset):
          # self.gdaIndexDict
          try:
            indexGDA = 0
            if(len(self.gdaIndexList) <= 0): 
              self.gdaIndexList = self.generateListOfGeneDiseaseAssociation(dataset)
            maxNumberOfThreads = 1000
            totalNumberOfthreads = len(dataset.gene_smybol)
            while(totalNumberOfthreads>0):
              if(totalNumberOfthreads<maxNumberOfThreads):
                maxNumberOfThreads = totalNumberOfthreads
              totalNumberOfthreads = totalNumberOfthreads - maxNumberOfThreads
              threads = list()
              while(len(threads)<maxNumberOfThreads):
                if(indexGDA<len(dataset.gene_smybol)):
                  x = threading.Thread(target=self.whileLoopWithThreads, args=(indexGDA,dataset,))
                  threads.append(x)
                  indexGDA+=1
                else:
                  break

              for x in threads:
                x.start()
              print("Total list of thread number : ", len(threads))
              # Wait for all of them to finish
              for x in threads:
                x.join()
            

            return self.gdaIndexDict
          except Exception as exc:
            print("generateDictOfGeneDiseaseAssociationBasedOnGene ", exc)

    def whileLoopWithThreads(self,indexGDA,dataset):
      index = 0
      diseaseIndexList = []
      if(indexGDA%100 == 0):
        print(datetime.now()," Index of the generateDictOfGeneDiseaseAssociationBasedOnGene : ", indexGDA)
      while(index<len(self.gdaIndexList)):
        if(dataset.edge_index[0][self.gdaIndexList[index]]<=dataset.edge_index[1][self.gdaIndexList[index]]):
          # check first node is gene or not
          firstNode = True if(dataset.gene_smybol[dataset.edge_index[0][self.gdaIndexList[index]]]!="") else False
          #firstNodeID = "" if(dataset.gene_smybol[randomIndex1]=="") else dataset.id[randomIndex1]
          # check second node is gene or not 
          # if node is gene it is assigned to True, otherwise assigned False
          secondNode = True if(dataset.gene_smybol[dataset.edge_index[1][self.gdaIndexList[index]]]!="") else False
          #secondNodeID = "" if(dataset.gene_smybol[randomIndex2]=="") else dataset.id[randomIndex2]
        
          if((firstNode and not secondNode) and (dataset.edge_index[0][self.gdaIndexList[index]] == indexGDA)):
            diseaseIndexList.append(self.gdaIndexList[index])
          elif((not firstNode and secondNode) and (dataset.edge_index[1][self.gdaIndexList[index]] == indexGDA)):
            diseaseIndexList.append(self.gdaIndexList[index])

        index += 1
      
      self.gdaIndexDict[indexGDA] = diseaseIndexList
      if(indexGDA%100 == 0):
        print(datetime.now()," Index of the generateDictOfGeneDiseaseAssociationBasedOnGene : ", indexGDA)
      return


    def _create_label(self, data: Data, index: Tensor, neg_edge_index: Tensor,baseTensor ,
                      out: Data ):

        edge_index = baseTensor

        """
        if hasattr(data, self.key):
            edge_label = data[self.key]
            assert edge_label.dtype == torch.long and edge_label.dim() == 1
            edge_label = edge_label[index].add_(1)
            delattr(data, self.key)
        else:
            edge_label = torch.ones(index.numel(), device=index.device)
        """

        edge_label = torch.ones(len(baseTensor[0]), device=index.device)

        if neg_edge_index.numel() > 0:
            neg_edge_label = edge_label.new_zeros(neg_edge_index.size(1))

        if self.split_labels:
            out[f'pos_{self.key}'] = edge_label
            out[f'pos_{self.key}_index'] = edge_index
            if neg_edge_index.numel() > 0:
                out[f'neg_{self.key}'] = neg_edge_label
                out[f'neg_{self.key}_index'] = neg_edge_index

        else:
            if neg_edge_index.numel() > 0:
                edge_label = torch.cat([edge_label, neg_edge_label], dim=0)
                edge_index = torch.cat([edge_index, neg_edge_index], dim=-1)
            out[self.key] = edge_label
            out[f'{self.key}_index'] = edge_index

        return out

    def __repr__(self) -> str:
        return (f'{self.__class__.__name__}(num_val={self.num_val}, '
                f'num_test={self.num_test})')

"""#KZCLinkSplit run

"""

dataFromGraphFile.x = dataFromGraphFile.x.float()
import torchvision
from torchvision import datasets,transforms
import torchvision.transforms as transforms

initVariables()
getNumberOfEdgesBetweenDiseaseGene()
getNumberOfEdgesBetweenGeneGeneOrDiseaseDisease()
buildGeneDiseaseEdgeIndexDict()
#print(geneDiseaseEdgeIndexDict)

transform = KZCLinkSplit(is_undirected=True, num_val=val_ratio,num_test=test_ratio,add_negative_train_samples=True)



splitEdgesBasedOnUniref50UsingDict()
transform.setLists(getEdgeLabelIndexFromIndex(train_edges_list), getEdgeLabelIndexFromIndex(val_edges_list), getEdgeLabelIndexFromIndex(test_edges_list))

train_data, val_data, test_data = transform(dataFromGraphFile)

"""!!!
# outputs of the model that contains :

Val Accuracy,  Val Precision, Val Recall, Val F1


Test Accuracy,  Test Precison,  Test Recall, Test F1
"""

dataFromGraphFile.x = dataFromGraphFile.x.float()
from torch_geometric.transforms import RandomLinkSplit
import os.path as osp
from sklearn.model_selection import KFold

import torch
from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score
import numpy as np
import torch_geometric.transforms as T
from torch_geometric.datasets import Planetoid
from torch_geometric.nn import GCNConv
from torch_geometric.utils import negative_sampling
from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset
import torchvision
from torchvision import datasets,transforms
import torchvision.transforms as transforms
from torch_geometric.utils import train_test_split_edges
from sklearn.metrics import roc_auc_score
from sklearn.metrics import average_precision_score, precision_recall_curve
from sklearn.metrics import auc


#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device = torch.device('cpu')
"""
transform = T.Compose([
    T.NormalizeFeatures(),
    T.ToDevice(device),
    T.RandomLinkSplit(num_val=0.1, num_test=0.1, is_undirected=True,
                      add_negative_train_samples=False),
])

train_data, val_data, test_data = transform(dataFromGraphFile)
"""
"""
path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'Planetoid')
dataset = Planetoid(path, name='Cora', transform=transform)
"""



"""
from torch_geometric.transforms import RandomLinkSplit

transform = RandomLinkSplit(is_undirected=True, num_val=0.1,num_test=0.1,add_negative_train_samples=False)

#train_data, val_data, test_data = transform(dataset[0])

train_data, val_data, test_data = transform(dataFromGraphFile)
"""

# After applying the `RandomLinkSplit` transform, the data is transformed from
# a data object to a list of tuples (train_data, val_data, test_data), with
# each element representing the corresponding split.
"""
train_data, val_data, test_data = dataset[0]
"""

"""# build networks, optimizers, loss functions , learning rate

# build hyper parameter tuning informations
"""

# 2 layer network
class Net1(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, out_channels)

    def encode(self, x, edge_index):
        x = self.conv1(x, edge_index).relu()
        return self.conv2(x, edge_index)

    def decode(self, z, edge_label_index):
        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)

    def decode_all(self, z):
        prob_adj = z @ z.t()
        return (prob_adj > 0).nonzero(as_tuple=False).t()

# 3 layer network
class Net2(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, middle_channels ,out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, middle_channels)
        self.conv3 = GCNConv(middle_channels, out_channels)

    def encode(self, x, edge_index):
        x = self.conv1(x, edge_index).relu()
        x = self.conv2(x, edge_index).relu()
        return self.conv3(x, edge_index)

    def decode(self, z, edge_label_index):
        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)

    def decode_all(self, z):
        prob_adj = z @ z.t()
        return (prob_adj > 0).nonzero(as_tuple=False).t()

# 4 layer network
class Net3(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, middle1_channels , middle2_channels ,out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, middle1_channels)
        self.conv3 = GCNConv(middle1_channels, middle2_channels)
        self.conv4 = GCNConv(middle2_channels, out_channels)

    def encode(self, x, edge_index):
        x = self.conv1(x, edge_index).relu()
        x = self.conv2(x, edge_index).relu()
        x = self.conv3(x, edge_index).relu()
        return self.conv4(x, edge_index)

    def decode(self, z, edge_label_index):
        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)

    def decode_all(self, z):
        prob_adj = z @ z.t()
        return (prob_adj > 0).nonzero(as_tuple=False).t()

# 5 layer network relu
class Net4(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, middle1_channels , middle2_channels ,middle3_channels ,out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, middle1_channels)
        self.conv3 = GCNConv(middle1_channels, middle2_channels)
        self.conv4 = GCNConv(middle2_channels, middle3_channels)
        self.conv5 = GCNConv(middle3_channels, out_channels)

    def encode(self, x, edge_index):
        x = self.conv1(x, edge_index).relu()
        x = self.conv2(x, edge_index).relu()
        x = self.conv3(x, edge_index).relu()
        x = self.conv4(x, edge_index).relu()
        return self.conv5(x, edge_index)

    def decode(self, z, edge_label_index):
        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)

    def decode_all(self, z):
        prob_adj = z @ z.t()
        return (prob_adj > 0).nonzero(as_tuple=False).t()


        # 5 layer network relu
class Net5(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, middle1_channels , middle2_channels ,middle3_channels ,middle4_channels, out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, middle1_channels)
        self.conv3 = GCNConv(middle1_channels, middle2_channels)
        self.conv4 = GCNConv(middle2_channels, middle3_channels)
        self.conv5 = GCNConv(middle3_channels, middle4_channels)
        self.conv6 = GCNConv(middle4_channels, out_channels)

    def encode(self, x, edge_index):
        x = self.conv1(x, edge_index).relu()
        x = self.conv2(x, edge_index).relu()
        x = self.conv3(x, edge_index).relu()
        x = self.conv4(x, edge_index).relu()
        x = self.conv5(x, edge_index).relu()
        return self.conv6(x, edge_index)

    def decode(self, z, edge_label_index):
        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)

    def decode_all(self, z):
        prob_adj = z @ z.t()
        return (prob_adj > 0).nonzero(as_tuple=False).t()


networks = [
    Net1(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/16), int(dataFromGraphFile.num_features/32)).to(device)
    ]

criterions = [
    torch.nn.L1Loss(),
    torch.nn.MSELoss(),
    torch.nn.CrossEntropyLoss(),
    torch.nn.CTCLoss(),
    torch.nn.NLLLoss(),
    torch.nn.PoissonNLLLoss(),
    torch.nn.GaussianNLLLoss(),
    torch.nn.KLDivLoss(),
    torch.nn.BCELoss(),
    torch.nn.BCEWithLogitsLoss(),
    torch.nn.MarginRankingLoss(),
    torch.nn.HingeEmbeddingLoss(),
    torch.nn.MultiLabelMarginLoss(),
    torch.nn.HuberLoss(),
    torch.nn.SmoothL1Loss(),
    torch.nn.SoftMarginLoss(),
    torch.nn.MultiLabelMarginLoss(),
    torch.nn.CosineEmbeddingLoss(),
    torch.nn.MultiMarginLoss(),
    torch.nn.TripletMarginLoss(),
    torch.nn.TripletMarginWithDistanceLoss()
]

elements = [
    [Net1(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/2), int(dataFromGraphFile.num_features/32)).to(device),torch.nn.PoissonNLLLoss()],
    [Net1(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/4), int(dataFromGraphFile.num_features/32)).to(device),torch.nn.PoissonNLLLoss()],
    [Net1(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/8), int(dataFromGraphFile.num_features/32)).to(device),torch.nn.PoissonNLLLoss()],
    [Net1(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/16), int(dataFromGraphFile.num_features/32)).to(device),torch.nn.PoissonNLLLoss()],
    [Net2(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/2), int(dataFromGraphFile.num_features/32),8).to(device),torch.nn.PoissonNLLLoss()],
    [Net2(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/4), int(dataFromGraphFile.num_features/32),8).to(device),torch.nn.PoissonNLLLoss()],
    [Net2(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/8), int(dataFromGraphFile.num_features/32),8).to(device),torch.nn.PoissonNLLLoss()],
    [Net2(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/16), int(dataFromGraphFile.num_features/32),8).to(device),torch.nn.PoissonNLLLoss()],
    [Net3(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/2), int(dataFromGraphFile.num_features/32),32,8).to(device),torch.nn.PoissonNLLLoss()],
    [Net3(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/4), int(dataFromGraphFile.num_features/32),32,8).to(device),torch.nn.PoissonNLLLoss()],
    [Net3(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/8), int(dataFromGraphFile.num_features/32),32,8).to(device),torch.nn.PoissonNLLLoss()],
    [Net3(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/16), int(dataFromGraphFile.num_features/32),32,16).to(device),torch.nn.PoissonNLLLoss()],
    [Net4(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/2), int(dataFromGraphFile.num_features/4),64,32,8).to(device),torch.nn.PoissonNLLLoss()],
    [Net4(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/2), int(dataFromGraphFile.num_features/16),64,32,8).to(device),torch.nn.PoissonNLLLoss()],
    [Net4(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/2), int(dataFromGraphFile.num_features/32),64,32,8).to(device),torch.nn.PoissonNLLLoss()],
    [Net4(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/4), int(dataFromGraphFile.num_features/4),64,32,8).to(device),torch.nn.PoissonNLLLoss()],
    [Net4(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/4), int(dataFromGraphFile.num_features/16),64,32,8).to(device),torch.nn.PoissonNLLLoss()],
    [Net4(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/4), int(dataFromGraphFile.num_features/32),64,32,8).to(device),torch.nn.PoissonNLLLoss()],
    [Net4(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/8), int(dataFromGraphFile.num_features/4),64,32,8).to(device),torch.nn.PoissonNLLLoss()],
    [Net4(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/8), int(dataFromGraphFile.num_features/16),64,32,8).to(device),torch.nn.PoissonNLLLoss()],
    [Net4(dataFromGraphFile.num_features, int(dataFromGraphFile.num_features/8), int(dataFromGraphFile.num_features/32),64,32,8).to(device),torch.nn.PoissonNLLLoss()]

]

class Model:

  def __init__(self,*parameters):

    self.setModel(parameters[0])
    self.setOptimizer(parameters[1])
    self.setLossFunction(parameters[2])

  def setModel(self,*modelParam):
    if(modelParam[0][0]=="Net1"):
      self.model = Net1(modelParam[0][1], modelParam[0][2], modelParam[0][3]).to(device)
    elif(modelParam[0][0]=="Net2"):
      self.model = Net2(modelParam[0][1], modelParam[0][2], modelParam[0][3], modelParam[0][4]).to(device)
    elif(modelParam[0][0]=="Net3"):
      self.model = Net3(modelParam[0][1], modelParam[0][2], modelParam[0][3], modelParam[0][4], modelParam[0][5]).to(device)
    elif(modelParam[0][0]=="Net4"):
      self.model = Net4(modelParam[0][1], modelParam[0][2], modelParam[0][3], modelParam[0][4], modelParam[0][5], modelParam[0][6]).to(device)
    elif(modelParam[0][0]=="Net5"):
      self.model = Net5(modelParam[0][1], modelParam[0][2], modelParam[0][3], modelParam[0][4], modelParam[0][5], modelParam[0][6], modelParam[0][7]).to(device)
    else:
      print("Not suitable format about Model")

  def setOptimizer(self,*optimizerParam):
    if(optimizerParam[0][0] == "Adadelta"):
      self.optimizer = torch.optim.Adadelta(params=self.model.parameters(),lr=optimizerParam[0][1])
    elif(optimizerParam[0][0] == "Adagrad"):
      self.optimizer = torch.optim.Adagrad(params=self.model.parameters(),lr=optimizerParam[0][1])
    elif(optimizerParam[0][0] == "Adam"):
      self.optimizer = torch.optim.Adam(params=self.model.parameters(),lr=optimizerParam[0][1])
    elif(optimizerParam[0][0] == "AdamW"):
      self.optimizer = torch.optim.AdamW(params=self.model.parameters(),lr=optimizerParam[0][1])
    elif(optimizerParam[0][0] == "SparseAdam"):
      self.optimizer = torch.optim.SparseAdam(params=self.model.parameters(),lr=optimizerParam[0][1])
    elif(optimizerParam[0][0] == "Adamax"):
      self.optimizer = torch.optim.Adamax(params=self.model.parameters(),lr=optimizerParam[0][1])
    elif(optimizerParam[0][0] == "ASGD"):
      self.optimizer = torch.optim.ASGD(params=self.model.parameters(),lr=optimizerParam[0][1])
    elif(optimizerParam[0][0] == "LBFGS"):
      self.optimizer = torch.optim.LBFGS(params=self.model.parameters(),lr=optimizerParam[0][1])
    elif(optimizerParam[0][0] == "NAdam"):
      self.optimizer = torch.optim.NAdam(params=self.model.parameters(),lr=optimizerParam[0][1])
    elif(optimizerParam[0][0] == "RAdam"):
      self.optimizer = torch.optim.RAdam(params=self.model.parameters(),lr=optimizerParam[0][1])
    elif(optimizerParam[0][0] == "RMSprop"):
      self.optimizer = torch.optim.RMSprop(params=self.model.parameters(),lr=optimizerParam[0][1])
    elif(optimizerParam[0][0] == "Rprop"):
      self.optimizer = torch.optim.Rprop(params=self.model.parameters(),lr=optimizerParam[0][1])
    elif(optimizerParam[0][0] == "SGD"):
      self.optimizer = torch.optim.SGD(params=self.model.parameters(),lr=optimizerParam[0][1])
    else:
      print("Not suitable format about optimizer")

  def setLossFunction(self,lossFuncName:str):
    if(lossFuncName == "L1Loss"):
      self.lossFunc =  torch.nn.L1Loss()
    elif(lossFuncName == "MSELoss"):
      self.lossFunc =  torch.nn.MSELoss()
    elif(lossFuncName == "CrossEntropyLoss"):
      self.lossFunc =  torch.nn.CrossEntropyLoss()
    elif(lossFuncName == "CTCLoss"):
      self.lossFunc =  torch.nn.CTCLoss()
    elif(lossFuncName == "NLLLoss"):
      self.lossFunc =  torch.nn.NLLLoss()
    elif(lossFuncName == "PoissonNLLLoss"):
      self.lossFunc =  torch.nn.PoissonNLLLoss()
    elif(lossFuncName == "GaussianNLLLoss"):
      self.lossFunc =  torch.nn.GaussianNLLLoss()
    elif(lossFuncName == "KLDivLoss"):
      self.lossFunc =  torch.nn.KLDivLoss()
    elif(lossFuncName == "BCELoss"):
      self.lossFunc =  torch.nn.BCELoss()
    elif(lossFuncName == "BCEWithLogitsLoss"):
      self.lossFunc =  torch.nn.BCEWithLogitsLoss()
    elif(lossFuncName == "MarginRankingLoss"):
      self.lossFunc =  torch.nn.MarginRankingLoss()
    elif(lossFuncName == "HingeEmbeddingLoss"):
      self.lossFunc =  torch.nn.HingeEmbeddingLoss()
    elif(lossFuncName == "MultiLabelMarginLoss"):
      self.lossFunc =  torch.nn.MultiLabelMarginLoss()
    elif(lossFuncName == "HuberLoss"):
      self.lossFunc =  torch.nn.HuberLoss()
    elif(lossFuncName == "SmoothL1Loss"):
      self.lossFunc =  torch.nn.SmoothL1Loss()
    elif(lossFuncName == "SoftMarginLoss"):
      self.lossFunc =  torch.nn.SoftMarginLoss()
    elif(lossFuncName == "CosineEmbeddingLoss"):
      self.lossFunc =  torch.nn.CosineEmbeddingLoss()
    elif(lossFuncName == "MultiMarginLoss"):
      self.lossFunc =  torch.nn.MultiMarginLoss()
    elif(lossFuncName == "TripletMarginLoss"):
      self.lossFunc =  torch.nn.TripletMarginLoss()
    elif(lossFuncName == "TripletMarginWithDistanceLoss"):
      self.lossFunc =  torch.nn.TripletMarginWithDistanceLoss()
    else:
      print("Not suitable format about loss function")

  def getModel(self):
    return self.model

  def getOptimizer(self):
    return self.optimizer

  def getLossFunc(self):
    return self.lossFunc

"""# model array"""

model = [
    Model(["Net1",1792,112,28], ["AdamW",0.001], "BCEWithLogitsLoss")
    ]

"""
# run hyper parameter tuning"""

print("Model Training operation is starting")
index = 0
max_val_accuracy=0
for element in model:
  try:
    prev_test_accuracy = 1
    model = element.getModel()
    criterion = element.getLossFunc()
    optimizer = element.getOptimizer()

    print("Working \n", "Model: ",model,  "\nLoss function: ",criterion, "\nOptimizer: ",optimizer)

    def train():
        model.train()
        optimizer.zero_grad()
        z = model.encode(train_data.x, train_data.edge_index)

        """We perform a new round of negative sampling for every training epoch:
        neg_edge_index = negative_sampling(
            edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,
            num_neg_samples=train_data.edge_label_index.size(1), method='sparse')

        edge_label_index = torch.cat(
            [train_data.edge_label_index, neg_edge_index],
            dim=-1,
        )
        edge_label = torch.cat([
            train_data.edge_label,
            train_data.edge_label.new_zeros(neg_edge_index.size(1))
        ], dim=0)
        """

        out = model.decode(z, train_data.edge_label_index).view(-1)
        loss = criterion(out, train_data.edge_label)
        loss.backward()
        optimizer.step()
        return loss


    @torch.no_grad()
    def testAccuracyScore(data):
        model.eval()
        z = model.encode(data.x, data.edge_index)
        out = model.decode(z, data.edge_label_index).view(-1).sigmoid()
        """
        print("data.edge_label: ",  data.edge_label)
        print("Out: ", out)
        print("Data Edge Label", data.edge_label.cpu().numpy())
        print("Old Output ", out.cpu().numpy())
        print("New Output ", np.around(out.cpu().numpy()))
        """
        #return accuracy_score(data.edge_label.cpu().numpy(), out.cpu().numpy())
        return [accuracy_score(data.edge_label.cpu().numpy(), np.around(out.cpu().numpy())),np.around(out.cpu().numpy())]

    @torch.no_grad()
    def testF1Score(data):
        model.eval()
        z = model.encode(data.x, data.edge_index)
        out = model.decode(z, data.edge_label_index).view(-1).sigmoid()
        """
        print("data.edge_label: ",  data.edge_label)
        print("Out: ", out)
        print("Data Edge Label", data.edge_label.cpu().numpy())
        print("Old Output ", out.cpu().numpy())
        print("New Output ", np.around(out.cpu().numpy()))
        """
        #return accuracy_score(data.edge_label.cpu().numpy(), out.cpu().numpy())
        return f1_score(data.edge_label.cpu().numpy(), np.around(out.cpu().numpy()))

    @torch.no_grad()
    def testPrecisionScore(data):
        model.eval()
        z = model.encode(data.x, data.edge_index)
        out = model.decode(z, data.edge_label_index).view(-1).sigmoid()
        """
        print("data.edge_label: ",  data.edge_label)
        print("Out: ", out)
        print("Data Edge Label", data.edge_label.cpu().numpy())
        print("Old Output ", out.cpu().numpy())
        print("New Output ", np.around(out.cpu().numpy()))
        """
        #return accuracy_score(data.edge_label.cpu().numpy(), out.cpu().numpy())
        return precision_score(data.edge_label.cpu().numpy(), np.around(out.cpu().numpy()))

    @torch.no_grad()
    def testRecallScore(data):
        model.eval()
        z = model.encode(data.x, data.edge_index)
        out = model.decode(z, data.edge_label_index).view(-1).sigmoid()
        """
        print("data.edge_label: ",  data.edge_label)
        print("Out: ", out)
        print("Data Edge Label", data.edge_label.cpu().numpy())
        print("Old Output ", out.cpu().numpy())
        print("New Output ", np.around(out.cpu().numpy()))
        """
        #return accuracy_score(data.edge_label.cpu().numpy(), out.cpu().numpy())
        return recall_score(data.edge_label.cpu().numpy(), np.around(out.cpu().numpy()))

    @torch.no_grad()
    def testSpecificityScore(data):
        model.eval()
        z = model.encode(data.x, data.edge_index)
        out = model.decode(z, data.edge_label_index).view(-1).sigmoid()
        """
        print("data.edge_label: ",  data.edge_label)
        print("Out: ", out)
        print("Data Edge Label", data.edge_label.cpu().numpy())
        print("Old Output ", out.cpu().numpy())
        print("New Output ", np.around(out.cpu().numpy()))
        """
        #return accuracy_score(data.edge_label.cpu().numpy(), out.cpu().numpy())
        return recall_score(np.logical_not(data.edge_label.cpu().numpy()), np.logical_not(np.around(out.cpu().numpy())))





    def train_epoch(model,device,dataloader,loss_fn,optimizer):
        train_loss,train_correct=0.0,0
        model.train()
        for images, labels in dataloader:

            images,labels = images.to(device),labels.to(device)
            optimizer.zero_grad()
            output = model(images)
            loss = loss_fn(output,labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * images.size(0)
            scores, predictions = torch.max(output.data, 1)
            train_correct += (predictions == labels).sum().item()

        return train_loss,train_correct

    def valid_epoch(model,device,dataloader,loss_fn):
      valid_loss, val_correct = 0.0, 0
      model.eval()
      with torch.no_grad():
        for images, labels in dataloader:

            images,labels = images.to(device),labels.to(device)
            output = model(images)
            loss=loss_fn(output,labels)
            valid_loss+=loss.item()*images.size(0)
            scores, predictions = torch.max(output.data,1)
            val_correct+=(predictions == labels).sum().item()

      return valid_loss,val_correct

    def test_epoch(model,device,dataloader,loss_fn):
      test_loss, test_correct = 0.0, 0
      model.eval()
      with torch.no_grad():
        for images, labels in dataloader:

            images,labels = images.to(device),labels.to(device)
            output = model(images)
            loss=loss_fn(output,labels)
            test_loss+=loss.item()*images.size(0)
            scores, predictions = torch.max(output.data,1)
            val_correct+=(predictions == labels).sum().item()

      return test_loss,test_correct

    @torch.no_grad()
    def testRocAuch(data):
        model.eval()
        z = model.encode(data.x, data.edge_index)
        out = model.decode(z, data.edge_label_index).view(-1).sigmoid()
        return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())

    def testPrAuch(data):
        model.eval()
        z = model.encode(data.x, data.edge_index)
        out = model.decode(z, data.edge_label_index).view(-1).sigmoid()
        # Data to plot precision - recall curve

        precision, recall, thresholds = precision_recall_curve(data.edge_label.cpu().detach().numpy(), out.cpu().detach().numpy())
        # Use AUC function to calculate the area under the curve of precision recall curve
        auc_precision_recall = auc(recall, precision)

        #average_precision = average_precision_score(data.edge_label.cpu().detach().numpy(), np.around(out.cpu().detach().numpy()))
        return (auc_precision_recall)

    def saveTestResult(dataset,valOrTest,testResult, epoch,test_accuracy, test_f1_score, test_precision, test_recall, test_roc_auc_score,testPrAucScore, test_specifity_score):
      index = 0
      resultHeader = ["Epoch ","Accuracy Score","F1-Score","Precision Score","Recall Score","Roc-Auc-Score","Pr-Auc Score","Specifity Score"]
      resultRow = [epoch,test_accuracy, test_f1_score, test_precision, test_recall, test_roc_auc_score,testPrAucScore , test_specifity_score]
      data=[]
      while(index<len(testResult)):
        tempData=[]
        tempData.append(dataset.id[dataset.edge_label_index[0][index]])
        tempData.append(dataset.id[dataset.edge_label_index[1][index]])
        tempData.append(dataset.edge_label[index].item())

        tempData.append(testResult[index])

        data.append(tempData)

        index+=1

      header = ['First Node', 'Second Node', 'Real Edge Status(1/0)', 'Predicted Edge Status(1/0)']
      if(valOrTest=="test"):
        with open("test-results"+str(datasetName)+".csv", 'w', encoding='UTF8') as f:
            writer = csv.writer(f)

            # write the header
            writer.writerow(header)

            # write the data
            writer.writerows(data)

            # write the header
            writer.writerow(resultHeader)

            # write the header
            writer.writerow(resultRow)
      elif(valOrTest=="val"):
        with open("val-results"+str(datasetName)+".csv", 'w', encoding='UTF8') as f:
            writer = csv.writer(f)

            # write the header
            writer.writerow(header)

            # write the data
            writer.writerows(data)

            # write the header
            writer.writerow(resultHeader)

            # write the header
            writer.writerow(resultRow)




    best_val_auc = final_test_auc = 0
    for epoch in range(1, 501):
      try:
        loss = train()
        val_accuracy, val_out_array = testAccuracyScore(val_data)
        test_accuracy, test_out_array= testAccuracyScore(test_data)

        val_precision = testPrecisionScore(val_data)
        test_precision = testPrecisionScore(test_data)
        val_recall = testRecallScore(val_data)
        test_recall = testRecallScore(test_data)
        #val_f1_score = test_f1_score(val_data)
        #test_f1_score = test_f1_score(test_data)
        val_roc_auc_score = testRocAuch(val_data)
        test_roc_auc_score = testRocAuch(test_data)
        val_specifity_score = testSpecificityScore(val_data)
        test_specifity_score = testSpecificityScore(test_data)
        testPrAucScore = testPrAuch(test_data)
        valPrAucScore = testPrAuch(val_data)
        if(max_val_accuracy<val_accuracy):
          max_val_accuracy = val_accuracy
          saveTestResult(test_data,"test",test_out_array, epoch,test_accuracy, (2*test_recall*test_precision)/(test_recall+test_precision), test_precision, test_recall, test_roc_auc_score, testPrAucScore,test_specifity_score)
          saveTestResult(val_data,"val",val_out_array, epoch ,val_accuracy, (2*val_recall*val_precision)/(val_recall+val_precision), val_precision, val_recall, val_roc_auc_score, valPrAucScore,val_specifity_score)
          torch.save(model, datasetName+"_model.pth")
          torch.save(model.state_dict(), datasetName+"_state_dict.pth")
          
        if epoch % 10 == 0:
          print("Epoch : ",epoch,
              "\n Val Accuracy: ", val_accuracy, "Val F1: ", (2*val_recall*val_precision)/(val_recall+val_precision), " Val Precision: ",val_precision, "Val Recall : ",val_recall, "Val Roc_Auc : ",val_roc_auc_score, "Val Pr_Auc : ",valPrAucScore," Val Specifity : ",val_specifity_score,
              "\n Test Accuracy: ", test_accuracy,  " Test F1: ", (2*test_recall*test_precision)/(test_recall+test_precision), " Test Precison: ",test_precision, " Test Recall: ", test_recall,  "Test Roc_Auc : ",test_roc_auc_score, "Test Pr_Auc : ",testPrAucScore ," Test Specifity : ",test_specifity_score)
      except Exception as exc:
        print("this eopch has a problem, exc: ", exc)

    print("Max val accuracy : ", max_val_accuracy)
  except:
    print("in this try we had a problem, please check upper informations")
