# -*- coding: utf-8 -*-
"""Build_Graph.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-NIT7bXU1on73Pk4wIH5uQTCZ6ObePvB
"""


"""!!!
#install pytorch packages
"""
#!pip install nltk
#!pip install tensorflow
#!pip install h5py
#!pip install -q transformers
#!pip install torch
#!pip install torchvision
#!pip install scikit-metrics

#!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html
#!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html
#!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git

"""!!!
#install scipy and networkx packages
"""

#!pip install 'scipy>=1.8'
#!pip install 'networkx<2.7'

"""# read disease decsription"""

#!!!!

import sys
import torch
try:
  print("Program Start with this argument : ", sys.argv[1])
  if(isinstance(float(sys.argv[1]), float)):
    MIN_SCORE = float(sys.argv[1])
  else:
    MIN_SCORE = 0.5
except Exception as exc:
  print("Exception : ", exc)

print("MIN_SCORE is ", str(MIN_SCORE))
#!!!!

import csv
rowsDiseaseDescription = []
with open("../../source-files/diseaseFeaturesWithDescription.csv", "r") as file:
    csvreader = csv.reader(file)
    headerDiseaseDescription = next(csvreader)
    for row in csvreader:
        rowsDiseaseDescription.append(row)

print(headerDiseaseDescription)
print(rowsDiseaseDescription[0])

"""!!!
#read gene features but we dont use that data
"""

import csv
rowsGeneFeatures = []
with open("../../source-files/GeneFeatures.csv", "r") as file:
    csvreader = csv.reader(file)
    headerGeneFeatures = next(csvreader)
    for row in csvreader:
        rowsGeneFeatures.append(row)

print(headerGeneFeatures)
print(rowsGeneFeatures[0])

# !
geneProteinSequenceDict = {}
counterForMeanLenght = 0
totalLenght = 0
for element in rowsGeneFeatures:
  if(len(element)>8 and element[2] != None and element[8] != None ):
    if(geneProteinSequenceDict.get(element[2]) == None):
      geneProteinSequenceDict[element[2]] = element[8]
      totalLenght+=len(element[8])
      counterForMeanLenght+=1

print(counterForMeanLenght)
print(totalLenght)
sequenceLenght = int(totalLenght/counterForMeanLenght)
sequenceLenght = sequenceLenght + ( 3 - sequenceLenght % 3)
print(sequenceLenght)
print(list(geneProteinSequenceDict.items())[0])

"""!!!
#read data from csv.

that data gathered from disgenet
"""

# !
import csv
rowsGeneDisease = []
with open("../../source-files/AllGeneDiseaseLinkedData40.csv", "r") as file:
    csvreader = csv.reader(file)
    headerGeneDisease = next(csvreader)
    indexNull = 0
    for row in csvreader:
      if(row != []):
        rowsGeneDisease.append(row)
      else:
        indexNull+=1

print(headerGeneDisease)
print("indexNull : ", indexNull)
print(len(rowsGeneDisease))
print(rowsGeneDisease[3])

"""# Build vectorizers"""

# !

geneFeaturesList = []
geneFeaturesDict = {}
geneIndex = 0
diseaseFeaturesList = []
diseaseFeaturesDict = {}
diseaseIndex = 0
index = 0
for element in rowsGeneDisease:
  if(index%1000 == 0):
    print("Index : ", index)
  index+=1
  if(len(element)>14 and element[14]!="" and float(element[14])>=MIN_SCORE):
    if(element[2]!=None):
      if(geneFeaturesDict.get(element[2]) == None and geneProteinSequenceDict.get(element[2]) != None ):
        geneFeaturesList.append(geneProteinSequenceDict[element[2]])
        geneFeaturesDict[element[2]]=geneIndex
        geneIndex+=1
    if(element[8] != None):
      for diseaseElement in rowsDiseaseDescription:
        if(len(diseaseElement)>7 and diseaseElement[0] == element[8]):
          if(diseaseFeaturesDict.get(element[8]) == None):
            #diseaseFeaturesList.append(diseaseElement[1]+" "+diseaseElement[7])
            diseaseFeaturesDict[element[8]]=diseaseElement[1]+" "+diseaseElement[7]
            diseaseIndex+=1

print(geneIndex, " ", diseaseIndex)

"""# Build protein sequence embedding

"""

import numpy as np
import h5py

with h5py.File("../../source-files/per-protein.h5", "r") as file:
    print(f"number of entries: {len(file.items())}")
    print(file)
    print(dir(file))
    print(type(file))

    for sequence_id, embedding in file.items():
      if sequence_id == "P04217":

        print("seq:", sequence_id, " protein embedding", embedding[0:embedding.size])

def proteinSequenceEmbedding(uniprotID):
  try:
    with h5py.File("../../source-files/per-protein.h5", "r") as file:

      for sequence_id, embedding in file.items():
        if sequence_id == uniprotID:
          return np.insert(embedding[0:embedding.size],0,np.zeros(768))

    return np.zeros(1792)
  except:
    print("An exception occurred")
    return np.zeros(1792)

vectorizedTemp = proteinSequenceEmbedding("P04217")
vectorizedTemp2 = proteinSequenceEmbedding("O95477")
vectorizedTemp3 = proteinSequenceEmbedding("O9123")
print(vectorizedTemp)
print(len(vectorizedTemp))
print(vectorizedTemp2)
print(len(vectorizedTemp2))
print(vectorizedTemp3)
print(len(vectorizedTemp3))
print(type(vectorizedTemp2))
print(type(vectorizedTemp2[0]))

"""# embedding function

# build biobert_v1.1
"""

#!pip install -q transformers

import re
import numpy as np
from transformers import AutoTokenizer, AutoModel

try:
  model = AutoModel.from_pretrained("../../source-files/")
  tokenizer = AutoTokenizer.from_pretrained("../../source-files/")
except Exception as exc:
  print("Biobert model did not found in the source-files path. Therefore, Biobert pretrained model will be downloaded from internet.")
  tokenizer = AutoTokenizer.from_pretrained("dmis-lab/biobert-v1.1")

  model = AutoModel.from_pretrained("dmis-lab/biobert-v1.1")

  print("Biobert pretrained model download process completed. Saving process will be run.")
  _ = model.save_pretrained("../../source-files/")
  _ = tokenizer.save_pretrained("../../source-files/")

"""#diseaseDescriptionEmbedding"""

def diseaseDescriptionEmbedding(description):
  try:
    inputs = tokenizer(description, return_tensors="pt",truncation=True, max_length=512)
    outputs = model(**inputs)
    vector = outputs["pooler_output"].detach().cpu().numpy()[0]
    return np.pad(vector, (0, 1024), 'constant')
  except:
    print("exception in diseaseDescriptionEmbedding ")
    return np.zeros(1792)

"""!!!
#build a dict that contains all gene symbol and disease id
"""

# !
import nltk
nltk.download('stopwords')
nltk.download('punkt')
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import re

minScore = MIN_SCORE
geneDiseaseDict = {}
indexGeneProcessed  = 0
indexDiseaseProcessed  = 0
try:

  for element in rowsGeneDisease:
    try:
      if(len(element) > 14 and element[14]!="" and float(element[14])>=MIN_SCORE):
        if(element[2]!=None):
          if(geneDiseaseDict.get(element[2]) == None and geneProteinSequenceDict.get(element[2]) != None ):
            #geneDiseaseDict[element[1]]=kMerAlgorithmForSequenceSlidingWindow(seq=geneProteinSequenceDict[element[1]],kMer=3)
            geneDiseaseDict[element[2]]=geneProteinSequenceDict[element[2]]
            indexGeneProcessed+=1
        if(element[8] != None):
          if(geneDiseaseDict.get(element[8]) == None):
            for diseaseElement in rowsDiseaseDescription:
              try:
                if(len(diseaseElement)>7 and diseaseElement[0] == element[8]):
                  py_nltk = re.sub(r'[^\w\s]',' ',(diseaseElement[1]+" "+diseaseElement[7]).lower())
                  text_tokens = word_tokenize(py_nltk)
                  py_nltk1 = stopwords.words ('english')
                  vector = [t for t in text_tokens if t not in py_nltk1]
                  #vector.split()
                  if(len(vector)>512):
                    tempVect = " ".join(vector[:511])
                    print(len(tempVect.split()),tempVect, "\n")
                    print(len(" ".join(vector).split())," ".join(vector), "\n")
                  else:
                    tempVect = " ".join(vector)

                  geneDiseaseDict[element[8]]=tempVect
                  indexDiseaseProcessed+=1
              except Exception as exc:
                print(exc)
    except Exception as exc:
      print(exc)
except:
  print("problem is here 1")

print("Processed gene : ", indexGeneProcessed, " processed disase : ", indexDiseaseProcessed)

print(headerDiseaseDescription)
print(rowsDiseaseDescription[0])

print("Lenght o the geneDisaseDict : ", len(list(geneDiseaseDict.items())))

"""# Build a graph via using networkx

"""

import matplotlib.pyplot as plt
import networkx as nx

# cv.transform([geneDiseaseDict.get("A1BG")]).toarray()
dictGeneSymbolUniprotID={}
#clear ram
bagOfWords = []

mainGraph = nx.Graph()
minScore= MIN_SCORE
index = 0
try:

  for element in rowsGeneDisease:
    try:
      if(element[14]!="" and float(element[14])>=minScore):
        if(element[1]!=None and element[2]!=None and element[8] != None and geneDiseaseDict.get(element[2]) != None and geneDiseaseDict.get(element[8]) != None):
          if(mainGraph.has_node(element[2]) == False):
            #mainGraph.add_nodes_from([(element[1], {'x': cv.transform([geneDiseaseDict.get(element[1])]).toarray()[0]})])
            dictGeneSymbolUniprotID[element[1]]=element[2]
            tempEmbeddingProt = proteinSequenceEmbedding(element[2])
            mainGraph.add_nodes_from([(element[2], {'x': tempEmbeddingProt,'id':element[2],"gene_smybol":element[1]})])
            #print(element[2], " " ,tempEmbeddingProt)
          if(mainGraph.has_node(element[8]) == False):
            #mainGraph.add_nodes_from([(element[8], {'x': cv.transform([geneDiseaseDict.get(element[8])]).toarray()[0]})])
            #print(geneDiseaseDict.get(element[8]))

            tempEmbeddingDisease = diseaseDescriptionEmbedding(geneDiseaseDict.get(element[8]))
            mainGraph.add_nodes_from([(element[8], {'x': tempEmbeddingDisease,'id':element[8],"gene_smybol":""})])
            #print(geneDiseaseDict.get(element[8]), " " ,tempEmbeddingDisease)

          if(mainGraph.has_edge(element[2],element[8]) == False):
            mainGraph.add_edge(element[2],element[8],edge_nodes_attributes=str(element[2]+","+element[8]))
            print("New edge is added, index : " , index)

          index+=1
        else:
          index+=1
    except Exception as exc:
      print(exc)
except:
  print("problem is here 2")

"""
attrs = {str(element[1]): {"geneid": element[0], "protein_class": element[6],"protein_class_name":element[7]},str(element[8]):{ "diseaseid": element[9],"disease_class":element[10],"disease_type":element[12]}}
nx.set_node_attributes(mainGraph,attrs)
"""

#from google.colab import drive
#drive.mount('/content/drive')

"""!!!
#read csv that contains disease disease associations
"""

# !
import csv
rowsDiseaseDisease = []
with open("../../source-files/AllDiseaseDiseaseLinkedData.csv", "r") as file:
    csvreader = csv.reader(file)
    headerDiseaseDisease = next(csvreader)
    for row in csvreader:
        rowsDiseaseDisease.append(row)

print(headerDiseaseDisease)
print(rowsDiseaseDisease[0])
print(len(rowsDiseaseDisease))

"""add association between diseases that 2 diseases are already in graph"""

for element in rowsDiseaseDisease:
  if(element[16]!=None and element[17] != None and geneDiseaseDict.get(element[16])!=None and geneDiseaseDict.get((element[17]))!=None and mainGraph.has_node(element[16]) == True and mainGraph.has_node(element[17]) == True ):
    mainGraph.add_edge(element[16],element[17],edge_nodes_attributes=str(element[16]+","+element[17]))

"""!!!
#read tab file that is contains gene-gene association.
"""

# !
import csv
rowsGeneGene = []
with open("../../source-files/BIOGRID-ORGANISM-Homo_sapiens-4.4.217.tab.txt", "r") as file:
    csvreader = csv.reader(file, delimiter='\t')
    headerGeneGene = next(csvreader)
    for row in csvreader:
        rowsGeneGene.append(row)

"""!!!
#add association that 2 genes are already i graph
"""

for element in rowsGeneGene:
  firstNodeUniprotID=dictGeneSymbolUniprotID.get(element[2])
  secondNodeUniprotID=dictGeneSymbolUniprotID.get(element[3])
  if(firstNodeUniprotID!=None and secondNodeUniprotID != None and geneDiseaseDict.get(firstNodeUniprotID)!=None and geneDiseaseDict.get(secondNodeUniprotID)!=None and mainGraph.has_node(firstNodeUniprotID) == True and mainGraph.has_node(secondNodeUniprotID) == True ):
    mainGraph.add_edge(firstNodeUniprotID,secondNodeUniprotID,edge_nodes_attributes=str(firstNodeUniprotID+","+secondNodeUniprotID))

"""# networkx to pytorch data"""

from torch_geometric.utils.convert import from_networkx

graphData = from_networkx(mainGraph)

"""!!!
#save dataset to drive
"""

import torch

torch.save(graphData,"../../graph-files/Graph_Own_"+str(MIN_SCORE)+".pt")

print("Graph is built successfully")